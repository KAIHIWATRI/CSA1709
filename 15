# Decision Tree from scratch (ID3 Algorithm)

import math
from collections import Counter

# Calculate entropy
def entropy(data, target_attr):
    values = [record[target_attr] for record in data]
    freq = Counter(values)
    ent = 0.0
    for f in freq.values():
        p = f / len(data)
        ent -= p * math.log2(p)
    return ent

# Information gain
def info_gain(data, attr, target_attr):
    values = [record[attr] for record in data]
    freq = Counter(values)
    subset_entropy = 0.0
    for v in freq.keys():
        subset = [record for record in data if record[attr] == v]
        subset_entropy += (len(subset) / len(data)) * entropy(subset, target_attr)
    return entropy(data, target_attr) - subset_entropy

# ID3 algorithm
def id3(data, attributes, target_attr):
    values = [record[target_attr] for record in data]
    # If all examples have same label → return label
    if values.count(values[0]) == len(values):
        return values[0]
    # If no attributes left → return majority
    if not attributes:
        return Counter(values).most_common(1)[0][0]

    # Best attribute
    gains = [info_gain(data, attr, target_attr) for attr in attributes]
    best_attr = attributes[gains.index(max(gains))]

    tree = {best_attr: {}}
    # For each value of best attribute → branch
    attr_values = set(record[best_attr] for record in data)
    for v in attr_values:
        subset = [record for record in data if record[best_attr] == v]
        if not subset:
            tree[best_attr][v] = Counter(values).most_common(1)[0][0]
        else:
            new_attrs = [a for a in attributes if a != best_attr]
            subtree = id3(subset, new_attrs, target_attr)
            tree[best_attr][v] = subtree
    return tree

# Prediction
def predict(tree, sample):
    if not isinstance(tree, dict):
        return tree
    attr = next(iter(tree))
    value = sample.get(attr)
    if value not in tree[attr]:
        return None  # unseen value
    return predict(tree[attr][value], sample)

# Example dataset (Play Tennis dataset)
data = [
    {"Outlook": "Sunny", "Temp": "Hot", "Humidity": "High", "Wind": "Weak", "Play": "No"},
    {"Outlook": "Sunny", "Temp": "Hot", "Humidity": "High", "Wind": "Strong", "Play": "No"},
    {"Outlook": "Overcast", "Temp": "Hot", "Humidity": "High", "Wind": "Weak", "Play": "Yes"},
    {"Outlook": "Rain", "Temp": "Mild", "Humidity": "High", "Wind": "Weak", "Play": "Yes"},
    {"Outlook": "Rain", "Temp": "Cool", "Humidity": "Normal", "Wind": "Weak", "Play": "Yes"},
    {"Outlook": "Rain", "Temp": "Cool", "Humidity": "Normal", "Wind": "Strong", "Play": "No"},
    {"Outlook": "Overcast", "Temp": "Cool", "Humidity": "Normal", "Wind": "Strong", "Play": "Yes"},
    {"Outlook": "Sunny", "Temp": "Mild", "Humidity": "High", "Wind": "Weak", "Play": "No"},
    {"Outlook": "Sunny", "Temp": "Cool", "Humidity": "Normal", "Wind": "Weak", "Play": "Yes"},
    {"Outlook": "Rain", "Temp": "Mild", "Humidity": "Normal", "Wind": "Weak", "Play": "Yes"},
    {"Outlook": "Sunny", "Temp": "Mild", "Humidity": "Normal", "Wind": "Strong", "Play": "Yes"},
    {"Outlook": "Overcast", "Temp": "Mild", "Humidity": "High", "Wind": "Strong", "Play": "Yes"},
    {"Outlook": "Overcast", "Temp": "Hot", "Humidity": "Normal", "Wind": "Weak", "Play": "Yes"},
    {"Outlook": "Rain", "Temp": "Mild", "Humidity": "High", "Wind": "Strong", "Play": "No"},
]

# Build tree
attributes = ["Outlook", "Temp", "Humidity", "Wind"]
tree = id3(data, attributes, "Play")

print("Decision Tree:", tree)

# Test prediction
sample = {"Outlook": "Sunny", "Temp": "Cool", "Humidity": "High", "Wind": "Strong"}
print("Prediction for sample:", predict(tree, sample))
